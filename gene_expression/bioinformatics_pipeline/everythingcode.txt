## Tag-based RNA-seq (Tag-Seq) reads processing pipeline, version November 9, 2023
# Created by Misha Matz (matz@utexas.edu), modified by Michael Studivan (studivanms@gmail.com) for use on the FAU KoKo HPC
# then modified by Allyson DeMerlis for use on the University of Miami HPC "Pegasus"

# put all raw reads into one directory: 1_fastq_rawreads

# they are all in .fastq.gz file format. First need to look at the reads and ensure that there are 4 lines per read (look for sequence headers)

gunzip SampleName.fastq.gz

# look at the reads
head -50 SampleName.fastq
# note that every read has four lines, the ID line starts with @HWI

#------------------------------

# first step: count the raw reads of each sample (converted countreads.pl to a bash script)

#!/bin/bash
#BSUB -J countrawreads
#BSUB -q general
#BSUB -P and_transcriptomics
#BSUB -n 8
#BSUB -W 120:00
#BSUB -o countrawreads.out
#BSUB -e countrawreads.err
#BSUB -u and128@miami.edu
#BSUB -N

#Purpose: counts the number of Illumina reads in a bunch of fastq files

#specify variables and paths

and="/scratch/projects/and_transcriptomics"

cd "/scratch/projects/and_transcriptomics/Ch2_temperaturevariability2023/1_fastq_rawreads"

output_file="countreads_results.txt"

glob=".fastq"
if [ ! -z "$1" ]; then
    glob="$1"
fi

fqs=(*$glob)
for f in "${fqs[@]}"; do
    gunzip -c "$f" > "temp.fastq"  # Decompress the file to a temporary file
    nrd=$(cat "temp.fastq" | wc -l)
    nrd=$((nrd / 4))
    echo "$f	$nrd"
    echo "$f	$nrd" >> "$output_file"  # Append the results to the output file
    rm "temp.fastq"  # Remove the temporary file
done

echo "Results have been saved to $output_file"

#------------------------------

# For the next step, I will be using TrimGalore to cutadapt.

# First, run these lines (if you haven't done this before) to install the conda packages (including cutadapt) so all the environments will work:

# module load
# conda config --add channels defaults
# conda config --add channels bioconda
# conda config --add channels conda-forge

# create cutadapt conda environment

conda create -n cutadaptenv cutadapt

# Modifications to Michael's code:
# 1. for Pegasus, you can't run "conda activate" within a LSF job, you have to active the conda environment first and then submit the job in that conda environment.
# 2. you can download all the .pl scripts from the tagseq github repository, but then you need to make them executable (run chmod +x scriptname.pl)
# 3. Also, you need to edit the header of each .pl script so it says "#!/usr/bin/env perl"

Michael's code:

#------------------------------
## Removing adaptors and low quality reads

conda activate cutadaptenv

echo '#!/bin/bash' > trim.sh
echo 'conda activate cutadaptenv' >> trim.sh
for F in *.fastq; do
echo "tagseq_clipper.pl $F | cutadapt - -a AAAAAAAA -a AGATCGG -q 15 -m 25 -o ${F/.fastq/}.trim" >>trim.sh;
done

# does not work with launcher_creator, consider breaking up script and running multiple jobs
sbatch -o trim.o%j -e trim.e%j --mem=200GB trim.sh

# checking the status of the job
squeue -u mstudiva

# double check you have the same number of files as samples
ll *.trim | wc -l

# did the trimming work?
head -100 SampleName.fastq | grep -E '^[NACGT]+$'
head -100 SampleName.trim | grep -E '^[NACGT]+$'
# the long runs of base A should be gone

# double-check that the rnaseq_clipper did not filter out too many reads by looking at the trim.e####### file
# make sure you're not losing too many reads to duplicates
# rename as a txt file
mv trim.e####### trim.txt

# to save time in case of issues, move the concatenated fastq files to backup directory
mv *.fastq ~/rawReads/

# to count the number of reads in trimmed samples
echo "countreads_trim.pl > countreads_trim.txt" > count_trim
launcher_creator.py -j count_trim -n count_trim -q shortq7 -t 6:00:00 -e studivanms@gmail.com
sbatch count_trim.slurm

#------------------------------
